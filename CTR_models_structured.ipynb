{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f3abb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Installation (compatible Python 3.12)\n",
    "!pip install torch pyro-ppl numpy pandas matplotlib scikit-learn arviz --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84517143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pyro.infer import MCMC, NUTS, SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Simuler donn√©es CTR\n",
    "n_docs = 5\n",
    "n_sessions = 1000\n",
    "true_relevance = np.random.beta(2, 5, size=n_docs)\n",
    "position_bias = np.linspace(1.0, 0.2, n_docs)\n",
    "\n",
    "click_data = []\n",
    "for _ in range(n_sessions):\n",
    "    session = []\n",
    "    for i in range(n_docs):\n",
    "        prob = true_relevance[i] * position_bias[i]\n",
    "        click = np.random.binomial(1, prob)\n",
    "        session.append(click)\n",
    "    click_data.append(session)\n",
    "\n",
    "click_df = pd.DataFrame(click_data, columns=[f'doc_{i+1}' for i in range(n_docs)])\n",
    "click_totals = click_df.sum(axis=0).values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c33c8f1",
   "metadata": {},
   "source": [
    "### Mod√®le 1 ‚Äì R√©gression Logistique Bay√©sienne (NUTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d66573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_model_1(click_totals, n_docs):\n",
    "    relevance = pyro.sample(\"relevance\", dist.Beta(torch.ones(n_docs), torch.ones(n_docs)))\n",
    "    exam_bias = pyro.sample(\"exam_bias\", dist.Beta(torch.ones(n_docs), torch.ones(n_docs)))\n",
    "    probs = relevance * exam_bias\n",
    "    with pyro.plate(\"data\", n_docs):\n",
    "        pyro.sample(\"clicks\", dist.Binomial(total_count=n_sessions, probs=probs),\n",
    "                    obs=torch.tensor(click_totals))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047781f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts_kernel = NUTS(click_model_1)\n",
    "mcmc = MCMC(nuts_kernel, num_samples=500, warmup_steps=200, num_chains=1)\n",
    "mcmc.run(click_totals, n_docs)\n",
    "samples = mcmc.get_samples()\n",
    "relevance_mean = samples[\"relevance\"].mean(0).numpy()\n",
    "exam_mean = samples[\"exam_bias\"].mean(0).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6902c8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(true_relevance, 'o-', label=\"Pertinence r√©elle\")\n",
    "plt.plot(relevance_mean, 's--', label=\"Estimation NUTS\")\n",
    "plt.title(\"Pertinence - Mod√®le 1 (NUTS)\")\n",
    "plt.xlabel(\"Document\")\n",
    "plt.ylabel(\"Pertinence\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ed5f3e",
   "metadata": {},
   "source": [
    "### Mod√®le 2 ‚Äì SVI (version scalaire initiale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f0f544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_nn_scalar(click_count, position):\n",
    "    weight = pyro.sample(\"weight\", dist.Normal(0., 1.))\n",
    "    bias = pyro.sample(\"bias\", dist.Normal(0., 1.))\n",
    "    prob = torch.sigmoid(weight * position + bias)\n",
    "    pyro.sample(\"click\", dist.Binomial(total_count=n_sessions, probs=prob),\n",
    "                obs=torch.tensor(click_count, dtype=torch.float32))\n",
    "\n",
    "def guide_nn_scalar(click_count, position):\n",
    "    weight_loc = pyro.param(\"weight_loc\", torch.tensor(0.))\n",
    "    weight_scale = pyro.param(\"weight_scale\", torch.tensor(1.), constraint=dist.constraints.positive)\n",
    "    bias_loc = pyro.param(\"bias_loc\", torch.tensor(0.))\n",
    "    bias_scale = pyro.param(\"bias_scale\", torch.tensor(1.), constraint=dist.constraints.positive)\n",
    "    pyro.sample(\"weight\", dist.Normal(weight_loc, weight_scale))\n",
    "    pyro.sample(\"bias\", dist.Normal(bias_loc, bias_scale))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafe0a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in range(n_docs):\n",
    "    pyro.clear_param_store()\n",
    "    click_count = click_totals[i]\n",
    "    position = position_bias[i]\n",
    "    svi = SVI(model_nn_scalar, guide_nn_scalar, Adam({\"lr\": 0.01}), loss=Trace_ELBO())\n",
    "    for step in range(1000):\n",
    "        svi.step(click_count, position)\n",
    "    w = pyro.param(\"weight_loc\").item()\n",
    "    b = pyro.param(\"bias_loc\").item()\n",
    "    results.append((w, b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cce9784",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [w for w, _ in results]\n",
    "plt.bar(range(1, n_docs + 1), weights)\n",
    "plt.title(\"Poids estim√©s (Mod√®le 2 - SVI Scalaire)\")\n",
    "plt.xlabel(\"Document\")\n",
    "plt.ylabel(\"Poids\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0aa3da7",
   "metadata": {},
   "source": [
    "### Mod√®le 3 ‚Äì SVI am√©lior√© (estimation directe de la pertinence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2499f55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_svi_improved(click_count, position):\n",
    "    relevance = pyro.sample(\"relevance\", dist.Beta(1., 1.))  # pertinence latente\n",
    "    logit = torch.log(position + 1e-6) + torch.log(relevance + 1e-6)\n",
    "    prob = torch.sigmoid(logit)\n",
    "    pyro.sample(\"click\", dist.Binomial(total_count=n_sessions, probs=prob),\n",
    "                obs=torch.tensor(click_count, dtype=torch.float32))\n",
    "\n",
    "def guide_svi_improved(click_count, position):\n",
    "    rel_alpha = pyro.param(\"rel_alpha\", torch.tensor(1.), constraint=dist.constraints.positive)\n",
    "    rel_beta = pyro.param(\"rel_beta\", torch.tensor(1.), constraint=dist.constraints.positive)\n",
    "    pyro.sample(\"relevance\", dist.Beta(rel_alpha, rel_beta))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c21398b",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_estimates = []\n",
    "\n",
    "for i in range(n_docs):\n",
    "    pyro.clear_param_store()\n",
    "    click_count = click_totals[i]\n",
    "    position = position_bias[i]\n",
    "\n",
    "    svi = SVI(model_svi_improved, guide_svi_improved, Adam({\"lr\": 0.01}), loss=Trace_ELBO())\n",
    "\n",
    "    for step in range(1000):\n",
    "        svi.step(click_count, position)\n",
    "\n",
    "    alpha = pyro.param(\"rel_alpha\").item()\n",
    "    beta = pyro.param(\"rel_beta\").item()\n",
    "    est = alpha / (alpha + beta)\n",
    "    relevance_estimates.append(est)\n",
    "    print(f\"üìÑ Doc {i+1} ‚Üí Pertinence estim√©e = {est:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a065a32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(true_relevance, 'o-', label=\"Pertinence r√©elle\")\n",
    "plt.plot(relevance_estimates, 's--', label=\"Estimation SVI am√©lior√©\")\n",
    "plt.title(\"Pertinence estim√©e (Mod√®le 3 - SVI am√©lior√©)\")\n",
    "plt.xlabel(\"Document\")\n",
    "plt.ylabel(\"Pertinence\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
