{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a468a3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Installation (compatible Python 3.12)\n",
    "!pip install torch pyro-ppl numpy pandas matplotlib scikit-learn arviz --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c4251b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pyro.infer import MCMC, NUTS, SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Simuler donn√©es CTR\n",
    "n_docs = 5\n",
    "n_sessions = 1000\n",
    "true_relevance = np.random.beta(2, 5, size=n_docs)\n",
    "position_bias = np.linspace(1.0, 0.2, n_docs)\n",
    "\n",
    "click_data = []\n",
    "for _ in range(n_sessions):\n",
    "    session = []\n",
    "    for i in range(n_docs):\n",
    "        prob = true_relevance[i] * position_bias[i]\n",
    "        click = np.random.binomial(1, prob)\n",
    "        session.append(click)\n",
    "    click_data.append(session)\n",
    "\n",
    "click_df = pd.DataFrame(click_data, columns=[f'doc_{i+1}' for i in range(n_docs)])\n",
    "click_totals = click_df.sum(axis=0).values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed55aec5",
   "metadata": {},
   "source": [
    "### Mod√®le 1 ‚Äì R√©gression Logistique Bay√©sienne (Pyro + NUTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50205210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_model_1(click_totals, n_docs):\n",
    "    relevance = pyro.sample(\"relevance\", dist.Beta(torch.ones(n_docs), torch.ones(n_docs)))\n",
    "    exam_bias = pyro.sample(\"exam_bias\", dist.Beta(torch.ones(n_docs), torch.ones(n_docs)))\n",
    "    probs = relevance * exam_bias\n",
    "    with pyro.plate(\"data\", n_docs):\n",
    "        pyro.sample(\"clicks\", dist.Binomial(total_count=n_sessions, probs=probs), obs=torch.tensor(click_totals))\n",
    "\n",
    "nuts_kernel = NUTS(click_model_1)\n",
    "mcmc = MCMC(nuts_kernel, num_samples=500, warmup_steps=200, num_chains=1)\n",
    "mcmc.run(click_totals, n_docs)\n",
    "\n",
    "samples = mcmc.get_samples()\n",
    "relevance_mean = samples[\"relevance\"].mean(0).numpy()\n",
    "exam_mean = samples[\"exam_bias\"].mean(0).numpy()\n",
    "\n",
    "plt.plot(true_relevance, 'o-', label=\"Pertinence r√©elle\")\n",
    "plt.plot(relevance_mean, 's--', label=\"Estimation NUTS\")\n",
    "plt.title(\"Pertinence - Mod√®le 1\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3895480",
   "metadata": {},
   "source": [
    "### Mod√®le 2 ‚Äì R√©seau Bay√©sien avec SVI (Forme scalaire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87dfed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_nn_scalar(click_count, position):\n",
    "    weight = pyro.sample(\"weight\", dist.Normal(0., 1.))\n",
    "    bias = pyro.sample(\"bias\", dist.Normal(0., 1.))\n",
    "    prob = torch.sigmoid(weight * position + bias)\n",
    "    pyro.sample(\"click\", dist.Binomial(total_count=n_sessions, probs=prob),\n",
    "                obs=torch.tensor(click_count, dtype=torch.float32))\n",
    "\n",
    "def guide_nn_scalar(click_count, position):\n",
    "    weight_loc = pyro.param(\"weight_loc\", torch.tensor(0.))\n",
    "    weight_scale = pyro.param(\"weight_scale\", torch.tensor(1.), constraint=dist.constraints.positive)\n",
    "    bias_loc = pyro.param(\"bias_loc\", torch.tensor(0.))\n",
    "    bias_scale = pyro.param(\"bias_scale\", torch.tensor(1.), constraint=dist.constraints.positive)\n",
    "    pyro.sample(\"weight\", dist.Normal(weight_loc, weight_scale))\n",
    "    pyro.sample(\"bias\", dist.Normal(bias_loc, bias_scale))\n",
    "\n",
    "results = []\n",
    "for i in range(n_docs):\n",
    "    pyro.clear_param_store()\n",
    "    click_count = click_totals[i]\n",
    "    position = position_bias[i]\n",
    "    svi = SVI(model_nn_scalar, guide_nn_scalar, Adam({\"lr\": 0.01}), loss=Trace_ELBO())\n",
    "    for step in range(1000):\n",
    "        svi.step(click_count, position)\n",
    "    w = pyro.param(\"weight_loc\").item()\n",
    "    b = pyro.param(\"bias_loc\").item()\n",
    "    results.append((w, b))\n",
    "\n",
    "weights = [w for w, _ in results]\n",
    "plt.bar(range(1, n_docs + 1), weights)\n",
    "plt.title(\"Poids estim√©s (SVI)\")\n",
    "plt.xlabel(\"Document\")\n",
    "plt.ylabel(\"Poids\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f78fb5",
   "metadata": {},
   "source": [
    "### Mod√®le 3 ‚Äì Classifieur Na√Øf Bay√©sien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8083b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.column_stack([position_bias] * n_sessions)\n",
    "y = np.array(click_data).flatten()\n",
    "X = X.flatten().reshape(-1, 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model_nb = GaussianNB()\n",
    "model_nb.fit(X_train, y_train)\n",
    "y_pred = model_nb.predict(X_test)\n",
    "acc_nb = accuracy_score(y_test, y_pred)\n",
    "print(f\"üéØ Pr√©cision du mod√®le Na√Øf Bay√©sien : {acc_nb:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac967c26",
   "metadata": {},
   "source": [
    "### Mod√®le 4 ‚Äì Arbre de D√©cision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad81da18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tree = DecisionTreeClassifier(max_depth=3, random_state=0)\n",
    "model_tree.fit(X_train, y_train)\n",
    "y_pred_tree = model_tree.predict(X_test)\n",
    "acc_tree = accuracy_score(y_test, y_pred_tree)\n",
    "print(f\"üéØ Pr√©cision de l'arbre de d√©cision : {acc_tree:.2%}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
